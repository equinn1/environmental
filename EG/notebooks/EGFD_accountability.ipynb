{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# East Greenwich Fire Department Accuntability Log Analysis\n",
    "\n",
    "E.Quinn 8/13/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/gquinn/EG/py_EGFD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FD_classes as pyEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ff(ffs,fname,lname,start_date,end_date):\n",
    "    ff = pyEG.FF(fname,lname,start_date,end_date)\n",
    "    name = ff.get_name()\n",
    "    ffs[name] = ff\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add firefighters to the roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs={}\n",
    "\n",
    "add_ff(ffs,'FF','Amaral',datetime.date(2017,1,7),datetime.date(2017,1,7))\n",
    "add_ff(ffs,'Daniel','Andrade',None,None)\n",
    "add_ff(ffs,'Seth','Archambault',None,None)\n",
    "add_ff(ffs,'Stephen','Babcock',None,None)\n",
    "add_ff(ffs,'Thomas','Bailey',None,None)\n",
    "add_ff(ffs,'Robert','Beaudreau',None,None)\n",
    "add_ff(ffs,'Andrew','Campbell',None,None)\n",
    "add_ff(ffs,'Martin','Columbier',None,None)\n",
    "add_ff(ffs,'Sean','Crute',datetime.date(2017,6,25),None)\n",
    "add_ff(ffs,'Anthony','DeLuca',None,None)\n",
    "add_ff(ffs,'Stephen','Forte',None,None)\n",
    "add_ff(ffs,'Robert','Gardner',None,None)\n",
    "add_ff(ffs,'David','Gorman',None,None)\n",
    "add_ff(ffs,'Ryan','Grady',None,None)\n",
    "add_ff(ffs,'Merton','Greene',None,None)\n",
    "add_ff(ffs,'Keith','Hall',None,None)\n",
    "add_ff(ffs,'Matthew','Howard',None,None)\n",
    "add_ff(ffs,'Michael','Jones',None,None)\n",
    "add_ff(ffs,'Kevin','King',None,None)\n",
    "add_ff(ffs,'Kevin','Lang',None,None)\n",
    "add_ff(ffs,'David','Lavallee',None,None)\n",
    "add_ff(ffs,'William','Marsh',None,None)\n",
    "add_ff(ffs,'Edward','Matola',None,None)\n",
    "add_ff(ffs,'Steven','McKeon',None,None)\n",
    "add_ff(ffs,'Thomas','Mears',None,None)\n",
    "add_ff(ffs,'Michael','Monaghan',None,None)\n",
    "add_ff(ffs,'Kenneth','Montville',None,None)\n",
    "add_ff(ffs,'Peter',\"O'Donnell\",None,None)\n",
    "add_ff(ffs,'James','Perry',None,None)\n",
    "add_ff(ffs,'William','Perry',None,None)\n",
    "add_ff(ffs,'Ronald','Preston',datetime.date(2017,6,25),None)\n",
    "add_ff(ffs,'William','Purcell',None,None)\n",
    "add_ff(ffs,'Joseph','Richardson',None,None)\n",
    "add_ff(ffs,'Gregg','Snowling',None,None)\n",
    "add_ff(ffs,'Brian','Stabile',None,None)\n",
    "add_ff(ffs,'Jonathan','Szerlag',None,None)\n",
    "add_ff(ffs,'FF','Squillante',None,datetime.date(2017,2,17))\n",
    "add_ff(ffs,'Robert','Warner',None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define platoons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platoons = {}\n",
    "\n",
    "for pid in ['A','B','C','D']:\n",
    "    platoons[pid] = pyEG.platoon(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platoons['A'].add_ff('OF1',ffs['Richardson, Joseph'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('OF2',ffs['Bailey, Thomas'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('OF3',ffs['Montville, Kenneth'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('OF4',ffs['Monaghan, Michael'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('FF1',ffs['Archambault, Seth'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('FF2',ffs[\"O'Donnell, Peter\"],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('FF3',ffs['Preston, Ronald'],datetime.date(2017,6,25),None)\n",
    "platoons['A'].add_ff('FF3',ffs['Amaral, FF'],datetime.date(2010,1,1),datetime.date(2017,1,7))\n",
    "platoons['A'].add_ff('FF4',ffs['Campbell, Andrew'],datetime.date(2010,1,1),None)\n",
    "platoons['A'].add_ff('FF5',ffs['DeLuca, Anthony'],datetime.date(2010,1,1),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platoons['B'].add_ff('OF1',ffs['Perry, William'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('OF2',ffs['Gardner, Robert'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('OF3',ffs['Beaudreau, Robert'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('OF4',ffs['Grady, Ryan'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('FF1',ffs['Columbier, Martin'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('FF2',ffs['Snowling, Gregg'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('FF3',ffs['Howard, Matthew'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('FF4',ffs['Crute, Sean'],datetime.date(2017,6,25),None)\n",
    "platoons['B'].add_ff('FF5',ffs['Perry, James'],datetime.date(2010,1,1),None)\n",
    "platoons['B'].add_ff('FF4',ffs['Squillante, FF'],datetime.date(2010,1,1),datetime.date(2017,2,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platoons['C'].add_ff('OF1',ffs['Mears, Thomas'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('OF2',ffs['Jones, Michael'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('OF3',ffs['Purcell, William'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('OF4',ffs['Greene, Merton'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('FF1',ffs['King, Kevin'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('FF2',ffs['Andrade, Daniel'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('FF3',ffs['Szerlag, Jonathan'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('FF4',ffs['Forte, Stephen'],datetime.date(2010,1,1),None)\n",
    "platoons['C'].add_ff('FF5',ffs['McKeon, Steven'],datetime.date(2010,1,1),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platoons['D'].add_ff('OF1',ffs['Hall, Keith'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('OF2',ffs['Babcock, Stephen'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('OF3',ffs['Warner, Robert'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('OF4',ffs['Matola, Edward'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('FF1',ffs['Marsh, William'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('FF2',ffs['Stabile, Brian'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('FF3',ffs['Lang, Kevin'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('FF4',ffs['Lavallee, David'],datetime.date(2010,1,1),None)\n",
    "platoons['D'].add_ff('FF5',ffs['Gorman, David'],datetime.date(2010,1,1),None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define scheduled shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = {}\n",
    "shift_count = 0\n",
    "\n",
    "base_date = {}\n",
    "base_date['A'] = datetime.datetime(2016,12,26,7,0,0)   #first cycle start 1/1/2017 07:00 or earlier for this platoon\n",
    "base_date['B'] = datetime.datetime(2016,12,28,7,0,0)\n",
    "base_date['C'] = datetime.datetime(2016,12,30,7,0,0)\n",
    "base_date['D'] = datetime.datetime(2017,1,1,7,0,0)\n",
    "\n",
    "for platoon in ['A','B','C','D']:\n",
    "    ts = base_date[platoon]\n",
    "    \n",
    "    while(ts.date() <= datetime.date(2018,5,20)):\n",
    "        cycle_start = ts\n",
    "        shifts[ts] = pyEG.shift(ts,platoon,platoons)   # first day shift\n",
    "        ts += datetime.timedelta(days=1)               # increment shift start by 1 day\n",
    "        shifts[ts] = pyEG.shift(ts,platoon,platoons)   # second day shift\n",
    "        ts += datetime.timedelta(days=1)               # increment shift start by 1 day\n",
    "        ts += datetime.timedelta(hours=10)             # increment shift start by 10 hours\n",
    "        shifts[ts] = pyEG.shift(ts,platoon,platoons)   # first night shift\n",
    "        ts += datetime.timedelta(days=1)               # increment shift start by 1 day\n",
    "        shifts[ts] = pyEG.shift(ts,platoon,platoons)   # second night shift\n",
    "        ts = cycle_start + datetime.timedelta(days=8) #start of next cycle\n",
    "        shift_count += 4\n",
    "        \n",
    "print(shift_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define 8-day cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cycles = {}\n",
    "\n",
    "cycle_count = 0\n",
    "\n",
    "for platoon in ['A','B','C','D']:\n",
    "    ts = base_date[platoon]\n",
    "    \n",
    "    while(ts.date() <= datetime.date(2018,5,20)):\n",
    "        cycle_count+=1\n",
    "\n",
    "        try:\n",
    "            cycles[ts] = pyEG.cycle(ts,shifts)\n",
    "        except KeyError:\n",
    "            ;\n",
    "        ts += datetime.timedelta(days=8)\n",
    "        \n",
    "print(cycle_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup dictionary to get accountability file names by FF\n",
    "\n",
    "These are the .csv files extracted from Eric's spreadsheet of accountability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {'Andrade, Daniel': 'FF_Andrade.csv', \\\n",
    "                       'Archambault, Seth': 'FF_Archambault.csv', \\\n",
    "                       'Babcock, Stephen': 'Lt_Babcock.csv', \\\n",
    "                       'Bailey, Thomas': 'Lt_Bailey.csv', \\\n",
    "                       'Beaudreau, Robert': 'Lt_Beaudreau.csv', \\\n",
    "                       'Campbell, Andrew': 'FF_Campbell.csv', \\\n",
    "                       'Columbier, Martin': 'FF_Columbier.csv', \\\n",
    "                       'Crute, Sean': 'Prob-FF_Crute.csv', \\\n",
    "                       'DeLuca, Anthony': 'FF_DeLuca.csv', \\\n",
    "                       'Forte, Stephen': 'FF_Forte.csv', \\\n",
    "                       'Gardner, Robert': 'Lt_Gardner.csv', \\\n",
    "                       'Gorman, David': 'Prob-FF_Gorman.csv', \\\n",
    "                       'Grady, Ryan': 'Lt_Grady.csv', \\\n",
    "                       'Greene, Merton': 'Lt_Greene.csv', \\\n",
    "                       'Hall, Keith': 'FF_Hall.csv', \\\n",
    "                       'Howard, Matthew': 'FF_Howard.csv', \\\n",
    "                       'Jones, Michael': 'Lt_Jones.csv', \\\n",
    "                       'King, Kevin': 'FF_King.csv',\n",
    "                       'Lang, Kevin': 'FF_Lang.csv', \\\n",
    "                       'Lavallee, David': 'Prob-FF_Lavallee.csv', \\\n",
    "                       'Marsh, William': 'FF_Marsh.csv', \\\n",
    "                       'Matola, Edward': 'Lt_Matola.csv', \\\n",
    "                       'McKeon, Steven': 'FF_McKeon.csv', \\\n",
    "                       'Mears, Thomas': 'Capt_Mears.csv', \\\n",
    "                       'Monaghan, Michael': 'Lt_Monaghan.csv', \\\n",
    "                       'Montville, Kenneth': 'Capt_Montville.csv', \\\n",
    "                       \"O'Donnell, Peter\": 'FF_ODonnell.csv', \\\n",
    "                       'Perry, James': 'Prob-FF_Perry.csv', \\\n",
    "                       'Perry, William': 'Lt_Perry.csv', \\\n",
    "                       'Preston, Ronald': 'Prob-FF_Preston.csv',  \\\n",
    "                       'Purcell, William': 'Lt_Purcell.csv', \\\n",
    "                       'Richardson, Joseph': 'Lt_Richardson.csv', \\\n",
    "                       'Snowling, Gregg': 'FF_Snowling.csv', \\\n",
    "                       'Stabile, Brian': 'FF_Stabile.csv', \\\n",
    "                       'Szerlag, Jonathan': 'FF_Szerlag.csv', \\\n",
    "                       'Warner, Robert': 'Lt_Warner.csv'}                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the accountability logs and add the data to the dictionaries\n",
    "\n",
    "There is one .csv file containing the accountability data for each firefighter\n",
    "\n",
    "Data elements are added to the dictionary for that firefighter and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ffid(platoons,dt,fname):\n",
    "    ff_id = None\n",
    "    for platoon in ['A','B','C','D']:\n",
    "        sc = pyEG.shift_crew(platoons,platoon,dt)\n",
    "        crew = sc.get_crew()\n",
    "        for ffid in crew.keys():\n",
    "            try:\n",
    "                if (crew[ffid]['FF'].get_name()==ff_name):\n",
    "                    ff_id = platoon + ffid \n",
    "            except KeyError:\n",
    "                continue\n",
    "    return(ff_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOccurrences(s, ch):\n",
    "    return [i for i, letter in enumerate(s) if letter == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reason(reason,ffid):\n",
    "    new_reason = ''\n",
    "    if (ffid is None):\n",
    "        new_reason += reason\n",
    "    else:\n",
    "        if ((',' in reason) & ('-' in reason)):\n",
    "            ix = findOccurrences(reason,'-')\n",
    "            ix_last = ix[len(ix)-1]\n",
    "            new_reason += ffid + reason[ix_last:]\n",
    "\n",
    "    return(new_reason)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct = {}\n",
    "    \n",
    "for ffid in ffs.keys():\n",
    "    ff = ffs[ffid]\n",
    "    ff_name = ff.get_name()\n",
    "\n",
    "    acct[ff_name] = {}\n",
    "    try:\n",
    "        fname = '../' + logs[ff_name]                                   #get the filename for this FF\n",
    "    except KeyError:\n",
    "        continue\n",
    "    acctdf = pd.read_csv(fname,parse_dates=[[0,1]],skiprows=2,header=None)   #read it\n",
    "    acctdf.rename(columns={'0_1': 'shift',2:'type',3:'hours',4:'rank',5:'reason'},inplace=True)\n",
    "    acctdf['FF_name'] = ff_name       #create a column for this FFs name\n",
    "\n",
    "    for index, row in acctdf.iterrows():    #loop through row by row and add data to dictionary\n",
    "        ff_name = row['FF_name']             #shifts dictionary key is FF name\n",
    "        shift = row['shift'].to_pydatetime()\n",
    "        dtv = datetime.datetime(shift.year,shift.month,shift.day,shift.hour,0,0)\n",
    "        acct[ff_name][dtv] = {}\n",
    "        typ = row['type']\n",
    "        acct[ff_name][dtv]['type'] = row['type']\n",
    "        acct[ff_name][dtv]['hours'] = float(row['hours'])\n",
    "        acct[ff_name][dtv]['rank'] = row['rank']\n",
    "        acct[ff_name][dtv]['reason'] = row['reason']\n",
    "        rstr = row['reason']                      #determine whose shift was being covered\n",
    "        for_ff = None                             #search for specific name in reason string\n",
    "        for_ffid = None\n",
    "        if isinstance(rstr, str):\n",
    "            if ('Andrade' in rstr):  for_ff = 'Andrade, Daniel'\n",
    "            if ('Archambault' in rstr):  for_ff = 'Archambault, Seth'\n",
    "            if ('Babcock' in rstr):  for_ff = 'Babcock, Stephen'\n",
    "            if ('Bailey' in rstr): for_ff = 'Bailey, Thomas'\n",
    "            if ('Beaudreau' in rstr): for_ff = 'Beaudreau, Robert'\n",
    "            if ('Campbell' in rstr): for_ff = 'Campbell, Andrew'\n",
    "            if ('Columbier' in rstr): for_ff = 'Columbier, Martin'\n",
    "            if ('Crute' in rstr): for_ff = 'Crute, Sean'\n",
    "            if ('DeLuca' in rstr): for_ff = 'DeLuca, Anthony'\n",
    "            if ('Forte' in rstr): for_ff = 'Forte, Stephen'\n",
    "            if ('Gardner' in rstr): for_ff = 'Gardner, Robert'\n",
    "            if ('Gorman' in rstr): for_ff = 'Gorman, David'\n",
    "            if ('Grady' in rstr): for_ff = 'Grady, Ryan'\n",
    "            if ('Greene' in rstr): for_ff = 'Greene, Merton'\n",
    "            if ('Hall' in rstr): for_ff = 'Hall, Keith'\n",
    "            if ('Howard' in rstr): for_ff = 'Howard, Matthew'\n",
    "            if ('Jones' in rstr): for_ff = 'Jones, Michael'\n",
    "            if ('King' in rstr): for_ff = 'King, Kevin'\n",
    "            if ('Lang' in rstr): for_ff = 'Lang, Kevin'\n",
    "            if ('Lavallee' in rstr): for_ff = 'Lavallee, David'\n",
    "            if ('Marsh' in rstr): for_ff = 'Marsh, William'\n",
    "            if ('Matola' in rstr): for_ff = 'Matola, Edward'\n",
    "            if ('McKeon' in rstr): for_ff = 'McKeon, Steven'\n",
    "            if ('Mears' in rstr): for_ff = 'Mears, Thomas'\n",
    "            if ('Monaghan' in rstr): for_ff = 'Monaghan, Michael'\n",
    "            if ('Montville' in rstr): for_ff = 'Montville, Kenneth'\n",
    "            if ('Donnell' in rstr): for_ff = \"O'Donnell, Peter\"\n",
    "            if ('FF Perry' in rstr): for_ff = 'Perry, James'\n",
    "            if ('Lt Perry' in rstr): for_ff = 'Perry, William'\n",
    "            if ('Preston' in rstr): for_ff = 'Preston, Ronald'\n",
    "            if ('Purcell' in rstr): for_ff = 'Purcell, William'\n",
    "            if ('Richardson' in rstr): for_ff = 'Richardson, Joseph'\n",
    "            if ('Snowling' in rstr): for_ff = 'Snowling, Gregg'\n",
    "            if ('Squillante' in rstr): for_ff = 'Squillante, FF'\n",
    "            if ('Stabile' in rstr): for_ff = 'Stabile, Brian'\n",
    "            if ('Szerlag' in rstr): for_ff = 'Szerlag, Jonathan'\n",
    "            if ('Warner' in rstr): for_ff = 'Warner, Robert'\n",
    "            acct[ff_name][dtv]['for_ff'] = for_ff    #save FF being covered\n",
    "            if (for_ff is not None):\n",
    "                for_ffid = get_ffid(platoons,dtv,for_ff)\n",
    "            acct[ff_name][dtv]['for_ff_id'] = for_ffid\n",
    "            acct[ff_name][dtv]['clean_reason'] = clean_reason(rstr,for_ffid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
