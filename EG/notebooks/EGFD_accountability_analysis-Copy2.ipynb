{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Analyze EGFD Accountability Data \n",
    "\n",
    "E.Quinn  7/28/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import struct\n",
    "from datetime import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary for looking up name by page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_name = {1: 'FF Andrade', 2: 'FF Archambault', 3: 'Lt Babcock', 4: 'Lt Bailey', 5: 'Lt Beaudreau', \\\n",
    "    6: 'FF Campbell', 7: 'FF Columbier', 8: 'Prob-FF Crute', 9: 'FF DeLuca', 10: 'FF Forte', \\\n",
    "    11: 'Lt Gardner', 12: 'Prob-FF Gorman', 13: 'Lt Grady', 14: 'Lt Greene', \\\n",
    "    15: 'Lt Hall', 16: 'FF Howard', 17: 'Lt Jones', 18: 'FF King', 19: 'FF Lang Jr.', 20: 'Prob-FF Lavallee', \\\n",
    "    21: 'FF Marsh', 22: 'Lt Matola, Jr.', 23: 'FF McKeon', 24: 'Capt Mears', 25: 'Lt Monaghan', \\\n",
    "    26: 'Capt Montville', 27: \"FF O'Donnell\", 28: 'Prob-FF Perry', 29: 'Lt Perry', 30: 'Prob-FF Preston', \\\n",
    "    31: 'Lt Purcell', 32: 'Lt Richardson', 33: 'FF Snowling', 34: 'FF Stabile', 35: 'FF Szerlag', 36: 'Lt Warner III'}                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary for looking up page by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_ID = {'FF Andrade': 1,'FF Archambault': 2,'Lt Babcock': 3,'Lt Bailey': 4,'Lt Beaudreau': 5,'FF Campbell': 6, \\\n",
    "         'FF Columbier': 7,'Prob-FF Crute': 8,'FF DeLuca': 9,'FF Forte': 10,'Lt Gardner': 11,'Prob-FF Gorman': 12, \\\n",
    "         'Lt Grady': 13,'Lt Greene': 14,'Lt Hall': 15,'FF Howard': 16,'Lt Jones': 17,'FF King': 18,'FF Lang Jr.': 19, \\\n",
    "         'Prob-FF Lavallee': 20,'FF Marsh': 21,'Lt Matola, Jr.': 22,'FF McKeon': 23,'Capt Mears': 24,'Lt Monaghan': 25, \\\n",
    "         'Capt Montville': 26,\"FF O'Donnell\": 27,'Prob-FF Perry': 28,'Lt Perry': 29,'Prob-FF Preston': 30,  \\\n",
    "         'Lt Purcell': 31,'Lt Richardson': 32,'FF Snowling': 33,'FF Stabile': 34,'FF Szerlag': 35,'Lt Warner III': 36}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of short names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_short_name = {1: 'FF DA', 2: 'FF SA', 3: 'Lt SB', 4: 'Lt TB', 5: 'Lt RB', 6: 'FF AC', \\\n",
    "         7: 'FF MC', 8: 'PFF SC', 9: 'FF AD', 10: 'FF SF', 11: 'Lt RG', 12: 'PFF DG', 13: 'Lt RG', 14: 'Lt MG',  \\\n",
    "         15: 'Lt KH', 16: 'FF MH', 17: 'Lt MJ', 18: 'FF KK', 19: 'FF KL', 20: 'PFF DL', 21: 'FF WM', \\\n",
    "         22: 'Lt EM', 23: 'FF SM', 24: 'Cpt TM', 25: 'Lt MM', 26: 'Cpt KM', 27: 'FF PO', 28: 'PFF JP',  \\\n",
    "         29: 'Lt BP', 30: 'PFF RP', 31: 'Lt WP', 32: 'Lt JR', 33: 'FF GS', 34: 'FF BS', 35: 'FF JS', 36: 'Lt RW'}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of initials by Page Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_initials = {1: 'DA', 2: 'SA', 3: 'SB', 4: 'TB', 5: 'RB', 6: 'AC', 7: 'MC', 8: 'SC', 9: 'AD', 10: 'SF', 11: 'RG',  \\\n",
    "         12: 'DG', 13: 'RG', 14: 'MG', 15: 'KH', 16: 'MH', 17: 'MJ', 18: 'KK', 19: 'KL', 20: 'DL', 21: 'WM', \\\n",
    "         22: 'EM', 23: 'SM', 24: 'TM', 25: 'MM', 26: 'KM', 27: 'PO', 28: 'JP', 29: 'WP', 30: 'RP', 31: 'WP', \\\n",
    "         32: 'JR', 33: 'GS', 34: 'BS', 35: 'JS', 36: 'RW'}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary for looking up platoon by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_platoon = {'FF Andrade': 'C','FF Archambault': 'A','Lt Babcock': 'D','Lt Bailey': 'A','Lt Beaudreau': 'B','FF Campbell': 'A', \\\n",
    "         'FF Columbier': 'B','Prob-FF Crute': 'B','FF DeLuca': 'A','FF Forte': 'C','Lt Gardner': 'B','Prob-FF Gorman': 'D', \\\n",
    "         'Lt Grady': 'B','Lt Greene': 'B','Lt Hall': 'D','FF Howard': 'B','Lt Jones': 'C','FF King': 'C','FF Lang Jr.': 'D', \\\n",
    "         'Prob-FF Lavallee': 'D','FF Marsh': 'D','Lt Matola, Jr.': 'D','FF McKeon': 'C','Capt Mears': 'C','Lt Monaghan': 'A', \\\n",
    "         'Capt Montville': 'A',\"FF O'Donnell\": 'A','Prob-FF Perry': 'B','Lt Perry': 'B','Prob-FF Preston': 'A',  \\\n",
    "         'Lt Purcell': 'C','Lt Richardson': 'A','FF Snowling': 'B','FF Stabile': 'D','FF Szerlag': 'C','Lt Warner III': 'D'}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary for looking up identifier by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_token = {'FF Andrade': 'CFF2','FF Archambault': 'AFF1','Lt Babcock': 'DOF2','Lt Bailey': 'AOF2', \\\n",
    "        'Lt Beaudreau': 'BOF3','FF Campbell': 'AFF4', \\\n",
    "        'FF Columbier': 'BFF1','Prob-FF Crute': 'BFF4','FF DeLuca': 'AFF5','FF Forte': 'CFF4', \\\n",
    "        'Lt Gardner': 'BOF2','Prob-FF Gorman': 'DFF5', \\\n",
    "        'Lt Grady': 'BOF4','Lt Greene': 'COF4','Lt Hall': 'DOF1','FF Howard': 'BFF3','Lt Jones': 'COF2', \\\n",
    "        'FF King': 'CFF1','FF Lang Jr.': 'DFF3', \\\n",
    "        'Prob-FF Lavallee': 'DFF4','FF Marsh': 'DFF1','Lt Matola, Jr.': 'DOF4','FF McKeon': 'CFF5', \\\n",
    "        'Capt Mears': 'COF1','Lt Monaghan': 'AOF4', \\\n",
    "        'Capt Montville': 'AOF3',\"FF O'Donnell\": 'AFF2','Prob-FF Perry': 'BFF5','Lt Perry': 'BOF1', \\\n",
    "        'Prob-FF Preston': 'AFF3', 'Lt Purcell': 'COF3','Lt Richardson': 'AOF1','FF Snowling': 'BFF2', \\\n",
    "        'FF Stabile': 'DFF2','FF Szerlag': 'CFF3','Lt Warner III': 'DOF3','FF Squillante':'EFF1'}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary for looking up name by identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_FF = {'CFF2':'FF Andrade','AFF1':'FF Archambault','DOF2':'Lt Babcock','AOF2':'Lt Bailey', \\\n",
    "        'BOF3':'Lt Beaudreau','AFF4':'FF Campbell', \\\n",
    "        'BFF1':'FF Columbier','BFF4':'Prob-FF Crute','AFF5':'FF DeLuca','CFF4':'FF Forte', \\\n",
    "        'BOF2':'Lt Gardner','DFF5':'Prob-FF Gorman', \\\n",
    "        'BOF4':'Lt Grady','COF4':'Lt Greene','DOF1':'Lt Hall','BFF3':'FF Howard','COF2':'Lt Jones', \\\n",
    "        'CFF1':'FF King','DFF3':'FF Lang Jr.', \\\n",
    "        'DFF4':'Prob-FF Lavallee','DFF1':'FF Marsh','DOF4':'Lt Matola, Jr.','CFF5':'FF McKeon', \\\n",
    "        'COF1':'Capt Mears','AOF4':'Lt Monaghan', \\\n",
    "        'AOF3':'Capt Montville','AFF2':\"FF O'Donnell\",'BFF5':'Prob-FF Perry','BOF1':'Lt Perry', \\\n",
    "        'AFF3':'Prob-FF Preston', 'COF3':'Lt Purcell','AOF1':'Lt Richardson','BFF2':'FF Snowling', \\\n",
    "        'DFF2':'FF Stabile','CFF3':'FF Szerlag','DOF3':'Lt Warner III','EFF1':'FF Squillante'}                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of 8-day cycle start times by platoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 8-Day Cycles\n",
      "A 69\n",
      "B 69\n",
      "C 69\n",
      "D 69\n"
     ]
    }
   ],
   "source": [
    "base_date = {}\n",
    "base_date['A'] = datetime.datetime(2016,12,26,7,0,0)   #first cycle start 1/1/2017 07:00 or earlier for this platoon\n",
    "base_date['B'] = datetime.datetime(2016,12,28,7,0,0)\n",
    "base_date['C'] = datetime.datetime(2016,12,30,7,0,0)\n",
    "base_date['D'] = datetime.datetime(2017,1,1,7,0,0)\n",
    "\n",
    "cycle_start = {}                                       # dictionary for cycle start by platoon\n",
    "\n",
    "max_datetime = datetime.datetime(2018,7,1,0,0,0)\n",
    "\n",
    "for shift_id in base_date.keys():                      # loop through earliest cycle start for each platoon\n",
    "    cycle_start[shift_id] = {}                         # create dictionary for platoon\n",
    "    ss = base_date[shift_id]                           # start with earliest cycle start time\n",
    "    while (ss < max_datetime):                         # loop until cycle start is past max_datetime\n",
    "        cycle_start[shift_id][ss] = {}                 # add dictionary for cycle start\n",
    "        ss += datetime.timedelta(days=8)               # increment cycle start by 8 days\n",
    "\n",
    "cycle_start\n",
    "\n",
    "print('Number of 8-Day Cycles')\n",
    "print('A ' + str(len(cycle_start['A'])))\n",
    "print('B ' + str(len(cycle_start['B'])))\n",
    "print('C ' + str(len(cycle_start['C'])))\n",
    "print('D ' + str(len(cycle_start['D'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': datetime.datetime(2016, 12, 26, 7, 0),\n",
       " 'B': datetime.datetime(2016, 12, 28, 7, 0),\n",
       " 'C': datetime.datetime(2016, 12, 30, 7, 0),\n",
       " 'D': datetime.datetime(2017, 1, 1, 7, 0)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build list of shifts for each FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = {}       \n",
    "\n",
    "for platoon in ['A','B','C','D']:\n",
    "    for ffn in ['OF1','OF2','OF3','OF4','FF1','FF2','FF3','FF4','FF5']:\n",
    "        token = platoon+ ffn\n",
    "        shifts[token] = {}\n",
    "        shifts[token]['name'] = token_FF[token]\n",
    "        shifts[token]['shifts'] = {}\n",
    "        for cycle in cycle_start[platoon]:\n",
    "            shift = cycle\n",
    "            shifts[token]['shifts'][shift] = {'type':'scheduled'}\n",
    "            shift += datetime.timedelta(days=1)   # increment cycle start by 10 hours + 1 day\n",
    "            shifts[token]['shifts'][shift] = {'type':'scheduled'}\n",
    "            shift += datetime.timedelta(days=1)\n",
    "            shift += datetime.timedelta(hours=10)   # increment cycle start by 10 hours + 1 day\n",
    "            shifts[token]['shifts'][shift] = {'type':'scheduled'}\n",
    "            shift += datetime.timedelta(days=1)   # increment cycle start by 1 day\n",
    "            shifts[token]['shifts'][shift] = {'type':'scheduled'}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup dictionary to get accountability file names by FF\n",
    "\n",
    "These are the .csv files extracted from Eric's spreadsheet of accountability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = {'FF Andrade': 'FF_Andrade.csv', \\\n",
    "                       'FF Archambault': 'FF_Archambault.csv', \\\n",
    "                       'Lt Babcock': 'Lt_Babcock.csv', \\\n",
    "                       'Lt Bailey': 'Lt_Bailey.csv', \\\n",
    "                       'Lt Beaudreau': 'Lt_Beaudreau.csv', \\\n",
    "                       'FF Campbell': 'FF_Campbell.csv', \\\n",
    "                       'FF Columbier': 'FF_Columbier.csv', \\\n",
    "                       'Prob-FF Crute': 'Prob-FF_Crute.csv', \\\n",
    "                       'FF DeLuca': 'FF_DeLuca.csv', \\\n",
    "                       'FF Forte': 'FF_Forte.csv', \\\n",
    "                       'Lt Gardner': 'Lt_Gardner.csv', \\\n",
    "                       'Prob-FF Gorman': 'Prob-FF_Gorman.csv', \\\n",
    "                       'Lt Grady': 'Lt_Grady.csv', \\\n",
    "                       'Lt Greene': 'Lt_Greene.csv', \\\n",
    "                       'Lt Hall': 'FF_Hall.csv', \\\n",
    "                       'FF Howard': 'FF_Howard.csv', \\\n",
    "                       'Lt Jones': 'Lt_Jones.csv', \\\n",
    "                       'FF King': 'FF_King.csv',\n",
    "                       'FF Lang Jr.': 'FF_Lang.csv', \\\n",
    "                       'Prob-FF Lavallee': 'Prob-FF_Lavallee.csv', \\\n",
    "                       'FF Marsh': 'FF_Marsh.csv', \\\n",
    "                       'Lt Matola, Jr.': 'Lt_Matola.csv', \\\n",
    "                       'FF McKeon': 'FF_McKeon.csv', \\\n",
    "                       'Capt Mears': 'Capt_Mears.csv', \\\n",
    "                       'Lt Monaghan': 'Lt_Monaghan.csv', \\\n",
    "                       'Capt Montville': 'Capt_Montville.csv', \\\n",
    "                       \"FF O'Donnell\": 'FF_ODonnell.csv', \\\n",
    "                       'Prob-FF Perry': 'Prob-FF_Perry.csv', \\\n",
    "                       'Lt Perry': 'Lt_Perry.csv', \\\n",
    "                       'Prob-FF Preston': 'Prob-FF_Preston.csv',  \\\n",
    "                       'Lt Purcell': 'Lt_Purcell.csv', \\\n",
    "                       'Lt Richardson': 'Lt_Richardson.csv', \\\n",
    "                       'FF Snowling': 'FF_Snowling.csv', \\\n",
    "                       'FF Stabile': 'FF_Stabile.csv', \\\n",
    "                       'FF Szerlag': 'FF_Szerlag.csv', \\\n",
    "                       'Lt Warner III': 'Lt_Warner.csv'}                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the accountability logs and add the data to the dictionaries\n",
    "\n",
    "There is one .csv file containing the accountability data for each firefighter\n",
    "\n",
    "Data elements are added to the dictionary for that firefighter and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOccurrences(s, ch):\n",
    "    return [i for i, letter in enumerate(s) if letter == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reason(reason,for_ff):\n",
    "    new_reason = ''\n",
    "    if (for_ff == ''):\n",
    "        new_reason += reason\n",
    "    else:\n",
    "        if ((',' in reason) & ('-' in reason)):\n",
    "            ix = findOccurrences(reason,'-')\n",
    "            ix_last = ix[len(ix)-1]\n",
    "            new_reason += FF_token[for_ff] + reason[ix_last:]\n",
    "\n",
    "    return(new_reason)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_acct(token):\n",
    "    \n",
    "    ff_name = token_FF[token]\n",
    "    fname = '../' + logs[ff_name]                                   #get the filename for this FF\n",
    "    acctdf = pd.read_csv(fname,parse_dates=[[0,1]],skiprows=2,header=None)   #read it\n",
    "    acctdf.rename(columns={'0_1': 'shift',2:'type',3:'hours',4:'rank',5:'reason'},inplace=True)\n",
    "    acctdf['FF_name'] = ff_name       #create a column for this FFs name\n",
    "    \n",
    "    for index, row in acctdf.iterrows():    #loop through row by row and add data to dictionary\n",
    "        ff_name = row['FF_name']             #shifts dictionary key is FF name\n",
    "        shift = row['shift'].to_pydatetime()\n",
    "        dtv = datetime.datetime(shift.year,shift.month,shift.day,shift.hour,0,0)\n",
    "        if dtv not in shifts[token]['shifts']:\n",
    "            shifts[token]['shifts'][dtv] = {}\n",
    "        \n",
    "        try:                                      #create dictionary for accountability data\n",
    "            sdict = shifts[token]['shifts'][dtv]['acct']\n",
    "        except KeyError:                          #if this shift was not found add it\n",
    "            shifts[token]['shifts'][dtv]['acct'] = {}\n",
    "            sdict = shifts[token]['shifts'][dtv]['acct']\n",
    "                                                  #fill in the accountability data elements\n",
    "        typ = row['type']\n",
    "        sdict['type'] = row['type']\n",
    "        sdict['hours'] = float(row['hours'])\n",
    "        sdict['rank'] = row['rank']\n",
    "        sdict['reason'] = row['reason']\n",
    "        rstr = row['reason']                      #determine whose shift was being covered\n",
    "        for_ff = ''                               #search for specific name in reason string\n",
    "        if isinstance(rstr, str):\n",
    "            if ('Andrade' in rstr):  for_ff = 'FF Andrade'\n",
    "            if ('Archambault' in rstr):  for_ff = 'FF Archambault'\n",
    "            if ('Babcock' in rstr):  for_ff = 'Lt Babcock'\n",
    "            if ('Bailey' in rstr): for_ff = 'Lt Bailey'\n",
    "            if ('Beaudreau' in rstr): for_ff = 'Lt Beaudreau'\n",
    "            if ('Campbell' in rstr): for_ff = 'FF Campbell'\n",
    "            if ('Columbier' in rstr): for_ff = 'FF Columbier'\n",
    "            if ('Crute' in rstr): for_ff = 'Prob-FF Crute'\n",
    "            if ('DeLuca' in rstr): for_ff = 'FF DeLuca'\n",
    "            if ('Forte' in rstr): for_ff = 'FF Forte'\n",
    "            if ('Gardner' in rstr): for_ff = 'Lt Gardner'\n",
    "            if ('Gorman' in rstr): for_ff = 'Prob-FF Gorman'\n",
    "            if ('Grady' in rstr): for_ff = 'Lt Grady'\n",
    "            if ('Greene' in rstr): for_ff = 'Lt Greene'\n",
    "            if ('Hall' in rstr): for_ff = 'Lt Hall'\n",
    "            if ('Howard' in rstr): for_ff = 'FF Howard'\n",
    "            if ('Jones' in rstr): for_ff = 'Lt Jones'\n",
    "            if ('King' in rstr): for_ff = 'FF King'\n",
    "            if ('Lang' in rstr): for_ff = 'FF Lang Jr.'\n",
    "            if ('Lavallee' in rstr): for_ff = 'Prob-FF Lavallee'\n",
    "            if ('Marsh' in rstr): for_ff = 'FF Marsh'\n",
    "            if ('Matola' in rstr): for_ff = 'Lt Matola, Jr.'\n",
    "            if ('McKeon' in rstr): for_ff = 'FF McKeon'\n",
    "            if ('Mears' in rstr): for_ff = 'Capt Mears'\n",
    "            if ('Monaghan' in rstr): for_ff = 'Lt Monaghan'\n",
    "            if ('Montville' in rstr): for_ff = 'Capt Montville'\n",
    "            if ('Donnell' in rstr): for_ff = \"FF O'Donnell\"\n",
    "            if ('FF Perry' in rstr): for_ff = 'Prob-FF Perry'\n",
    "            if ('Lt Perry' in rstr): for_ff = 'Lt Perry'\n",
    "            if ('Preston' in rstr): for_ff = 'Prob-FF Preston'\n",
    "            if ('Purcell' in rstr): for_ff = 'Lt Purcell'\n",
    "            if ('Richardson' in rstr): for_ff = 'Lt Richardson'\n",
    "            if ('Snowling' in rstr): for_ff = 'FF Snowling'\n",
    "            if ('Squillante' in rstr): for_ff = 'FF Squillante'\n",
    "            if ('Stabile' in rstr): for_ff = 'FF Stabile'\n",
    "            if ('Szerlag' in rstr): for_ff = 'FF Szerlag'\n",
    "            if ('Warner' in rstr): for_ff = 'Lt Warner III'\n",
    "            if (len(for_ff) > 0):\n",
    "                shifts[token]['shifts'][dtv]['acct']['for_token'] = FF_token[for_ff]    #save FF being covered\n",
    "            else:\n",
    "                shifts[token]['shifts'][dtv]['acct']['for_token'] = ''  #no for_ff\n",
    "            shifts[token]['shifts'][dtv]['acct']['clean_reason'] = clean_reason(rstr,for_ff)\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in shifts.keys():\n",
    "    read_acct(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#shifts['AFF1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write web page displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cellcolor(token,ts,shifts):\n",
    "    bgcolor = '#FFFFFF'\n",
    "    try:\n",
    "        typ = shifts[token]['shifts'][ts]['acct']['type']\n",
    "        if (typ == 'VC'): bgcolor = '#C0C0C0'\n",
    "        if (typ == 'IOD'): bgcolor = '#FF00FF'\n",
    "        if (typ in ['PRS','BER']): bgcolor = '#FFFF00'\n",
    "        if ('CS-' in typ): bgcolor = '#00FF00'\n",
    "        if ('C-' in typ): bgcolor = '#00FF00'\n",
    "    except KeyError:\n",
    "        x=1\n",
    "    return(bgcolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2(token,ts,shifts):\n",
    "    l2str = '<br>'\n",
    "    try:\n",
    "        typ = shifts[token]['shifts'][ts]['acct']['type']\n",
    "        tag = token + str(ts)\n",
    "        if (typ in ['VC','IOD','SWAP','SWAPW','SL','PRS','BER']): \n",
    "            l2str += '<a href=\"#' + tag + '\">' + typ + '</a>'\n",
    "        if ('OT-' in typ): l2str += '<a href=\"#' + tag + '\">' + typ + '</a>'\n",
    "        if (('C-' in typ) | ('CS-' in typ)): l2str += '<a href=\"#' + tag + '\">' + typ + '</a>'\n",
    "    except KeyError:\n",
    "        ;\n",
    "    return(l2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line3(token,ts,shifts):\n",
    "    l3str = '<br>'\n",
    "    \n",
    "    try:\n",
    "        if (shifts[token]['shifts'][ts]['acct']['for_token'] != ''):\n",
    "            token2 = shifts[token]['shifts'][ts]['acct']['for_token']\n",
    "            tag = token2 + str(ts)\n",
    "            l3str += '<a href=\"#' + tag + '\">' + token2 + '</a>'\n",
    "        else:\n",
    "            for token2 in shifts.keys():\n",
    "                try:\n",
    "                    if (shifts[token2]['shifts'][ts]['acct']['for_token'] == token):\n",
    "                        tag = token2 + str(ts)\n",
    "                        l3str += '<a href=\"#' + tag + '\">' + token2 + '</a>'\n",
    "                except KeyError:\n",
    "                    ;\n",
    "\n",
    "    except KeyError:\n",
    "            ;\n",
    "    return(l3str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftabl(token,year,month,hour,shifts,file):        \n",
    "    ndays = {1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:31,9:30,10:31,11:30,12:31}\n",
    "    if (hour == 7): \n",
    "        full_shift=10\n",
    "        rowstr = '<tr align=\"center\"><td rowspan=\"2\">' + str(month) + '/' + str(year) + '</td>'\n",
    "        rowstr +='<td>07:00</td>'\n",
    "    else: \n",
    "        full_shift=14\n",
    "        rowstr = '<tr><td>17:00</td>'\n",
    "    \n",
    "    for d in range(1,1+ndays[month]):\n",
    "        ts = datetime.datetime(year,month,d,hour,0,0)\n",
    "        tag = token + str(ts)\n",
    "        \n",
    "        rowstr += '<td bgcolor=\"' + cellcolor(token,ts,shifts) + '\">'\n",
    "        \n",
    "                                                        #see if we are scheduled this shift\n",
    "        try:\n",
    "            if (shifts[token]['shifts'][ts]['type']=='scheduled'):   #see if there is an entry for this timestamp\n",
    "                rowstr += 'On'\n",
    "        except KeyError:\n",
    "            rowstr += '&nbsp;'\n",
    "        rowstr += line2(token,ts,shifts)\n",
    "        rowstr += line3(token,ts,shifts)\n",
    "        rowstr += '</td>'\n",
    "    file.write(rowstr + '</tr>\\n')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../test_V2.html','w') \n",
    "\n",
    "file.write('<html><body>') \n",
    "\n",
    "for token in shifts.keys():\n",
    "    ff_name = token_FF[token]\n",
    "    file.write('<a name=\"' + ff_name + '\">')\n",
    "    file.write('<h2>' + token + ' ' + '</h2></a>\\n')\n",
    "    file.write('<table border=\"1\">\\n')\n",
    "    \n",
    "    file.write('<tr><td>Month</td><td>Shift</td>')\n",
    "    for d in range(1,32):\n",
    "        file.write('<td>' + str(d) + '</td>')\n",
    "    file.write('</tr>\\n')\n",
    "    \n",
    "    year = 2017\n",
    "    month = 1\n",
    "    \n",
    "    for i in range(1,18):\n",
    "            \n",
    "        shiftabl(token,year,month,7,shifts,file)  \n",
    "        shiftabl(token,year,month,17,shifts,file) \n",
    "        \n",
    "        month += 1\n",
    "        if (month > 12):\n",
    "            year += 1\n",
    "            month = 1\n",
    "        \n",
    "    file.write('</table>\\n')\n",
    "    \n",
    "for token in shifts.keys():\n",
    "    ff_name = token_FF[token]\n",
    "    file.write('<a name=\"acct_' + token + '\">\\n')\n",
    "    file.write('<h2>' + token + ' ' + '</h2></a>\\n')\n",
    "    file.write('<table border=\"1\">\\n')\n",
    "    file.write('<tr><td>Shift</td><td>Type</td><td>Hours</td><td>Rank</td><td>Reason</td></tr>\\n')\n",
    "\n",
    "    for shift in shifts[token]['shifts'].keys():\n",
    "        sdict = shifts[token]['shifts'][shift]\n",
    "        try:\n",
    "            entry_type = sdict['acct']['type']\n",
    "            hours = sdict['acct']['hours']\n",
    "            rank = sdict['acct']['rank']\n",
    "            reason = sdict['acct']['clean_reason']\n",
    "            tag = token + str(shift)\n",
    "            file.write('<tr><td><a name=\"' + tag + '\"></a>' + str(shift) + '</td>')\n",
    "            file.write('<td>' + entry_type + '</td>')\n",
    "            file.write('<td>' + str(hours) + '</td>')\n",
    "            file.write('<td>' + rank + '</td>')\n",
    "            file.write('<td>' + str(reason) + '</td></tr>\\n')\n",
    "        except KeyError:\n",
    "            continue\n",
    "    file.write('</table>\\n')\n",
    "\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lt Richardson\n",
      "Lt Bailey\n",
      "Capt Montville\n",
      "Lt Monaghan\n",
      "FF Archambault\n",
      "FF O'Donnell\n",
      "Prob-FF Preston\n",
      "FF Campbell\n",
      "FF DeLuca\n",
      "Lt Perry\n",
      "Lt Gardner\n",
      "Lt Beaudreau\n",
      "Lt Grady\n",
      "FF Columbier\n",
      "FF Snowling\n",
      "FF Howard\n",
      "Prob-FF Crute\n",
      "Prob-FF Perry\n",
      "Capt Mears\n",
      "Lt Jones\n",
      "Lt Purcell\n",
      "Lt Greene\n",
      "FF King\n",
      "FF Andrade\n",
      "FF Szerlag\n",
      "FF Forte\n",
      "FF McKeon\n",
      "Lt Hall\n",
      "Lt Babcock\n",
      "Lt Warner III\n",
      "Lt Matola, Jr.\n",
      "FF Marsh\n",
      "FF Stabile\n",
      "FF Lang Jr.\n",
      "Prob-FF Lavallee\n",
      "Prob-FF Gorman\n"
     ]
    }
   ],
   "source": [
    "for token in shifts.keys():\n",
    "    print(token_FF[token])\n",
    "    for shift in shifts[token]:\n",
    "        try:\n",
    "            typ = shifts[token]['shifts'][shift]['acct']['type']\n",
    "            if typ in ['VC','SL','PER','IOD']:\n",
    "                print(str(shift) + ' ' + typ)\n",
    "                for ff_covering in shifts.keys():\n",
    "                    try:\n",
    "                        for_ff = shifts[ff_covering]['shifts'][shift]['acct']['for_ff']\n",
    "                        if (for_ff == ff_name):\n",
    "                            print(str(shift)+ ' ' + ff_covering + ' covering for: ' + for_ff )\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for token in shifts:\n",
    "    for shift in shifts[token]['shifts']:\n",
    "        try:\n",
    "            typ = shifts[token]['shifts'][shift]['acct']['type']\n",
    "            if (typ == 'GT'): print(token_FF[token])\n",
    "            if (typ in counts.keys()):\n",
    "                counts[typ] += 1\n",
    "            else:\n",
    "                counts[typ] = 1\n",
    "        except KeyError:\n",
    "            ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SWAP': 445,\n",
       " 'VC': 679,\n",
       " 'SL': 432,\n",
       " 'PRS': 78,\n",
       " 'OT-VC': 618,\n",
       " 'OT-PRS': 71,\n",
       " 'OT-BERV': 23,\n",
       " 'OT-SL': 365,\n",
       " 'SWAPW': 441,\n",
       " 'OT': 428,\n",
       " 'DP': 48,\n",
       " 'OT-ADM': 64,\n",
       " 'OT-BARG': 15,\n",
       " 'OT-IOD': 545,\n",
       " 'OT-COMP': 62,\n",
       " 'CS-APP': 7,\n",
       " 'C-DD': 365,\n",
       " 'CS-SO': 12,\n",
       " 'C-ND': 325,\n",
       " 'OT-EOD': 6,\n",
       " 'IOD': 858,\n",
       " 'CMP-U': 75,\n",
       " 'ADMIN': 73,\n",
       " 'CS-TRN': 14,\n",
       " 'CMP-E': 76,\n",
       " 'CT': 2,\n",
       " 'C-FP': 8,\n",
       " 'C-TRN': 5,\n",
       " 'OFF': 1,\n",
       " 'BER': 37,\n",
       " 'ACTOT': 9,\n",
       " 'SCH': 3,\n",
       " 'C-DIVE': 14,\n",
       " 'BARG': 16,\n",
       " 'OT-VNCY': 64,\n",
       " 'ACT': 68,\n",
       " 'CS-EMS': 101,\n",
       " 'UT': 2,\n",
       " 'CS-FP': 2,\n",
       " 'CS-FA': 122,\n",
       " 'CS-SCBA': 7,\n",
       " 'OT-SCH': 3,\n",
       " 'C-BM': 15,\n",
       " 'DFP': 8,\n",
       " 'OT-EMERG': 2,\n",
       " 'C-APP': 1,\n",
       " 'EMER': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for situation of alleged 'gaming' OT and VAC\n",
    "\n",
    "Scenario:  FF1 takes a vacation day, FF2 gets OT for covering FF1's vacation day\n",
    "           Later in FF1's 8 day cycle, FF2 takes a vacation day and FF1 gets OT for covering it.\n",
    "           \n",
    "Algorithm: \n",
    "\n",
    "            For each FF, look at 8-day cycles in which he took a vacation day (or other day requiring coverage).  \n",
    "\n",
    "            See if, in this 8-day cycle, this FF was paid for covering a day taken by the FF who covered his. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " match_count = 0\n",
    "\n",
    "for ff_name in shifts.keys():                          # loop through FF list\n",
    "    platoon = FF_platoon[ff_name]                      # get the platoon (A,B,C,D) for this FF\n",
    "    ff_id = FF_ID[ff_name]                             # get page number\n",
    "    print('Processing ' + ff_name + ' ' + str(ff_id) + ' ' + platoon)           # display name and id #\n",
    "    for first_shift in cycle_start[platoon]:           # loop through shift start times that begin an 8-day cycle\n",
    "        cycle_shifts = []                              # fill in the other shift start times for that cycle\n",
    "        ts = first_shift\n",
    "        for day in range(1,9):\n",
    "            cycle_shifts.append(ts)\n",
    "            ts += datetime.timedelta(hours=10)          \n",
    "            cycle_shifts.append(ts)\n",
    "            ts += datetime.timedelta(hours=14)\n",
    "        for ts in cycle_shifts:                                      # loop through the shifts for this 8-day cycle\n",
    "            try:\n",
    "                stype = shifts[ff_name][ts]['acct']['type']          # get accountability log entry if there is one\n",
    "                if (stype in ['VC','SL','PRS','ADM','BER','ACT']):   # see if coverage may be required\n",
    "                    print(ff_name + ' ' + str(ts) + ' ' + stype)    \n",
    "                    for ff_cover in shifts.keys():                   # see who covered this shift\n",
    "                        if (ff_cover != 'ff_name'):\n",
    "                            try:\n",
    "                                if (shifts[ff_cover][ts]['acct']['for_id'] == ff_id):\n",
    "                                    print('covered by: ' + ff_cover )\n",
    "                                    cover_id = FF_ID[ff_cover]\n",
    "                                    for cs in cycle_shifts:          # see if the ff who covered was himself covered\n",
    "                                        try:                         # by the ff we are processing in this cycle\n",
    "                                            if (shifts[ff_name][cs]['acct']['for_id'] == cover_id):\n",
    "                                                typ = shifts[ff_name][cs]['acct']['type']\n",
    "                                                print('match########## ' + str(cs) + ' ' + ff_name + ' for ' + ff_cover + ' ' + typ)\n",
    "                                                if ('SWAP' not in typ): match_count += 1\n",
    "                                        except KeyError:\n",
    "                                            continue\n",
    "                            except KeyError:\n",
    "                                continue\n",
    "            except KeyError:\n",
    "                continue                                             #get here if no accountability log\n",
    "                                \n",
    "print(match_count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptabl(platoon,ts,shifts,file):        \n",
    "    file.write('<tr><td>' + str(ts) + '</td><td>' + platoon + '</td>')\n",
    "    for i in range(1,5):\n",
    "        ff_desig = 'OF' + platoon + str(i)\n",
    "        ff_name = desig_FF[ff_desig]\n",
    "        ff_cover = chk_cov(ff_name,ts)\n",
    "        tag = ff_desig + str(ts)\n",
    "        tds =('<td>')\n",
    "        try:\n",
    "            typ = shifts[ff_name]['shifts'][ts]['acct']['type']\n",
    "            if (typ == 'IOD'):                      # set background purple for IOD\n",
    "                tds = '<td bgcolor=\"#FF00FF\">'\n",
    "            if (typ == 'SL'):                       # set background gray for SL\n",
    "                tds = '<td bgcolor=\"#C0C0C0\">'\n",
    "            if (typ == 'VC'):                       # set background light blue for VC\n",
    "                tds = '<td bgcolor=\"#00FFFF\">'\n",
    "            if ((typ == 'PRS') | (typ == 'BER')):   # set background yellow for personal and bereavement \n",
    "                tds = '<td bgcolor=\"#FFFF00\">'\n",
    "            file.write(tds + '<a href=\"#' + tag + '\">' + typ + '</a>')\n",
    "        except KeyError:\n",
    "            file.write(tds + 'On')\n",
    "        if (len(ff_cover) > 2):\n",
    "            cover_tag = FF_desig[ff_cover] + str(ts)\n",
    "            file.write('<br><a href=\"#' + cover_tag + '\">' + ff_cover + '</a>')\n",
    "        file.write('</td>')\n",
    "    for i in range(1,6):\n",
    "        ff_desig = 'FF' + platoon + str(i)\n",
    "        ff_name = desig_FF[ff_desig]\n",
    "        ff_cover = chk_cov(ff_name,ts)\n",
    "        tds =('<td>')\n",
    "        try:\n",
    "            typ = shifts[ff_name]['shifts'][ts]['acct']['type']\n",
    "            tag = ff_desig + str(ts)\n",
    "            if (typ == 'IOD'):                      # set background purple for IOD\n",
    "                tds = '<td bgcolor=\"#FF00FF\">'\n",
    "            if (typ == 'SL'):                       # set background gray for SL\n",
    "                tds = '<td bgcolor=\"#C0C0C0\">'\n",
    "            if (typ == 'VC'):                       # set background light blue for VC\n",
    "                tds = '<td bgcolor=\"#00FFFF\">'\n",
    "            if ((typ == 'PRS') | (typ == 'BER')):   # set background yellow for personal and bereavement \n",
    "                tds = '<td bgcolor=\"#FFFF00\">'\n",
    "            file.write(tds + '<a href=\"#' + tag + '\">' + typ + '</a>')\n",
    "        except KeyError:\n",
    "            if ((ff_name == 'Prob-FF Preston') & (ts < datetime.datetime(2017,6,1,0,0,0))):\n",
    "                file.write(tds + 'NA')\n",
    "            else:\n",
    "                file.write(tds + 'On')\n",
    "        if (len(ff_cover) > 2):\n",
    "            cover_tag = FF_desig[ff_cover] + str(ts)\n",
    "            file.write('<br><a href=\"#' + cover_tag + '\">' + ff_cover + '</a>')\n",
    "        file.write('</td>')\n",
    "    file.write('</tr>\\n')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../platoons.html','w') \n",
    "\n",
    "file.write('<html><body>') \n",
    "\n",
    "for platoon in ['A','B','C','D']:\n",
    "    file.write('<h2>Platoon: ' + platoon + '</h2></a>\\n')\n",
    "    file.write('<table border=\"1\">\\n')\n",
    "    file.write('<tr><td>&nbsp;</td><td>&nbsp;</td>')\n",
    "    for i in range(1,5):\n",
    "        file.write('<td>OF' + platoon + str(i) + '</td>')\n",
    "    for i in range(1,6):\n",
    "        file.write('<td>FF' + platoon + str(i) + '</td>')\n",
    "    file.write('</tr>\\n')\n",
    "    file.write('<tr><td>Shift</td><td>P</td>')\n",
    "    for i in range(1,5):\n",
    "        des = 'OF' + platoon + str(i)\n",
    "        file.write('<td>'+ desig_FF[des] + '</td>')\n",
    "    for i in range(1,6):\n",
    "        des = 'FF' + platoon + str(i)\n",
    "        file.write('<td>' + desig_FF[des]+ '</td>')\n",
    "    file.write('</tr>\\n')\n",
    "        \n",
    "    for ts in cycle_start[platoon]:\n",
    "        if (ts < datetime.datetime(2018,5,21,1,0,0)):\n",
    "            ts2 = ts\n",
    "            ptabl(platoon,ts2,shifts,file)\n",
    "            ts2 += datetime.timedelta(days=1)   #increment shift start by 1 day\n",
    "            ptabl(platoon,ts2,shifts,file)\n",
    "            ts2 += datetime.timedelta(days=1)   #increment shift start by 1 day\n",
    "            ts2 += datetime.timedelta(hours=10)   #increment shift start 10 hours\n",
    "            ptabl(platoon,ts2,shifts,file)\n",
    "            ts2 += datetime.timedelta(days=1)   #increment shift start by 1 day\n",
    "            ptabl(platoon,ts2,shifts,file)\n",
    "    file.write('</table>\\n')\n",
    "\n",
    "acct_webpage(file,shifts)          #write webpage of accountability data with links\n",
    "\n",
    "file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
